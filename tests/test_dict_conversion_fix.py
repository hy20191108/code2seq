"""
è¾æ›¸å¤‰æ›ä¿®æ­£ãƒ†ã‚¹ãƒˆ

common.pyã®SingleTimeStepPredictionã§ç™ºç”Ÿã™ã‚‹numpyé…åˆ—â†’è¾æ›¸å¤‰æ›ã®
å•é¡Œã‚’æ¤œè¨¼ã—ã€ä¿®æ­£æ¡ˆã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import pickle
from typing import Any, List, Optional

import numpy as np


# å•é¡Œã®ã‚ã‚‹ã‚ªãƒªã‚¸ãƒŠãƒ«å®Ÿè£…ï¼ˆsimplified versionï¼‰
class OriginalSingleTimeStepPrediction:
    def __init__(self, prediction: str, attention_paths: Optional[List[Any]]) -> None:
        self.prediction = prediction
        if attention_paths is not None:
            paths_with_scores = []
            for (
                attention_score,
                vector,
                path_context_info,
                source_vector,
                target_vector,
                astpath_vector,
            ) in attention_paths:
                # å•é¡Œï¼šnumpyé…åˆ—ã‚’ãã®ã¾ã¾è¾æ›¸ã«æ ¼ç´
                path_context_dict = {
                    "score": attention_score,
                    "vector": vector,  # â† numpy.ndarray
                    "source": getattr(path_context_info, "source", "test_source"),
                    "target": getattr(path_context_info, "target", "test_target"),
                    "path": getattr(path_context_info, "longPath", "test_path"),
                    "source_vector": source_vector,
                    "target_vector": target_vector,
                    "astpath_vector": astpath_vector,
                }
                paths_with_scores.append(path_context_dict)
            self.attention_paths = paths_with_scores


# ä¿®æ­£ã•ã‚ŒãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆnumpyé…åˆ—ã‚’ä¿æŒï¼‰
class FixedSingleTimeStepPrediction:
    def __init__(self, prediction: str, attention_paths: Optional[List[Any]]) -> None:
        self.prediction = prediction
        if attention_paths is not None:
            paths_with_scores = []
            for (
                attention_score,
                vector,
                path_context_info,
                source_vector,
                target_vector,
                astpath_vector,
            ) in attention_paths:
                # ä¿®æ­£ï¼šnumpyé…åˆ—ã®å‹ã‚’æ˜ç¤ºçš„ã«ä¿æŒ
                path_context_dict = {
                    "score": attention_score,
                    "vector": np.asarray(vector),  # â† æ˜ç¤ºçš„ã«numpyé…åˆ—ã¨ã—ã¦ä¿æŒ
                    "source": getattr(path_context_info, "source", "test_source"),
                    "target": getattr(path_context_info, "target", "test_target"),
                    "path": getattr(path_context_info, "longPath", "test_path"),
                    "source_vector": np.asarray(source_vector)
                    if source_vector is not None
                    else None,
                    "target_vector": np.asarray(target_vector)
                    if target_vector is not None
                    else None,
                    "astpath_vector": np.asarray(astpath_vector)
                    if astpath_vector is not None
                    else None,
                }
                paths_with_scores.append(path_context_dict)
            self.attention_paths = paths_with_scores


class MockPathContextInfo:
    """ãƒ†ã‚¹ãƒˆç”¨ã®PathContextInfo"""

    def __init__(self, source="test_source", target="test_target", path="test_path"):
        self.source = source
        self.target = target
        self.longPath = path


def create_test_data():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    # numpyé…åˆ—ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆ
    vector = np.random.random(320).astype(np.float32)
    source_vector = np.random.random(128).astype(np.float32)
    target_vector = np.random.random(128).astype(np.float32)
    astpath_vector = np.random.random(256).astype(np.float32)

    # PathContextInfo
    pc_info = MockPathContextInfo()

    # attention_pathsãƒ‡ãƒ¼ã‚¿
    attention_paths = [
        (
            0.85,  # attention_score
            vector,  # vector
            pc_info,  # path_context_info
            source_vector,  # source_vector
            target_vector,  # target_vector
            astpath_vector,  # astpath_vector
        )
    ]

    return attention_paths, vector, source_vector, target_vector, astpath_vector


def test_original_implementation():
    """ã‚ªãƒªã‚¸ãƒŠãƒ«å®Ÿè£…ã§ã®å‹å¤‰æ›å•é¡Œã‚’æ¤œè¨¼"""
    print("=== ã‚ªãƒªã‚¸ãƒŠãƒ«å®Ÿè£…ãƒ†ã‚¹ãƒˆ ===")

    attention_paths, vector, source_vector, target_vector, astpath_vector = (
        create_test_data()
    )

    # ã‚ªãƒªã‚¸ãƒŠãƒ«å®Ÿè£…ã§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
    original = OriginalSingleTimeStepPrediction("test_prediction", attention_paths)

    # pickleç›´åˆ—åŒ–/é€†ç›´åˆ—åŒ–
    serialized = pickle.dumps(original)
    deserialized = pickle.loads(serialized)

    # å‹ãƒã‚§ãƒƒã‚¯
    path_context_dict = deserialized.attention_paths[0]

    print(f"vectorå‹: {type(path_context_dict['vector'])}")
    print(f"source_vectorå‹: {type(path_context_dict['source_vector'])}")
    print(f"target_vectorå‹: {type(path_context_dict['target_vector'])}")
    print(f"astpath_vectorå‹: {type(path_context_dict['astpath_vector'])}")

    # å‹å¤‰æ›ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    vector_is_numpy = isinstance(path_context_dict["vector"], np.ndarray)
    source_vector_is_numpy = isinstance(path_context_dict["source_vector"], np.ndarray)

    print(f"vector is numpy: {vector_is_numpy}")
    print(f"source_vector is numpy: {source_vector_is_numpy}")

    return vector_is_numpy, source_vector_is_numpy


def test_fixed_implementation():
    """ä¿®æ­£å®Ÿè£…ã§ã®å‹ä¿æŒã‚’æ¤œè¨¼"""
    print("\n=== ä¿®æ­£å®Ÿè£…ãƒ†ã‚¹ãƒˆ ===")

    attention_paths, vector, source_vector, target_vector, astpath_vector = (
        create_test_data()
    )

    # ä¿®æ­£å®Ÿè£…ã§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
    fixed = FixedSingleTimeStepPrediction("test_prediction", attention_paths)

    # pickleç›´åˆ—åŒ–/é€†ç›´åˆ—åŒ–
    serialized = pickle.dumps(fixed)
    deserialized = pickle.loads(serialized)

    # å‹ãƒã‚§ãƒƒã‚¯
    path_context_dict = deserialized.attention_paths[0]

    print(f"vectorå‹: {type(path_context_dict['vector'])}")
    print(f"source_vectorå‹: {type(path_context_dict['source_vector'])}")
    print(f"target_vectorå‹: {type(path_context_dict['target_vector'])}")
    print(f"astpath_vectorå‹: {type(path_context_dict['astpath_vector'])}")

    # å‹ãŒä¿æŒã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    vector_is_numpy = isinstance(path_context_dict["vector"], np.ndarray)
    source_vector_is_numpy = isinstance(path_context_dict["source_vector"], np.ndarray)

    print(f"vector is numpy: {vector_is_numpy}")
    print(f"source_vector is numpy: {source_vector_is_numpy}")

    return vector_is_numpy, source_vector_is_numpy


def test_dict_access_compatibility():
    """è¾æ›¸ã‚¢ã‚¯ã‚»ã‚¹ã®äº’æ›æ€§ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n=== è¾æ›¸ã‚¢ã‚¯ã‚»ã‚¹äº’æ›æ€§ãƒ†ã‚¹ãƒˆ ===")

    attention_paths, vector, source_vector, target_vector, astpath_vector = (
        create_test_data()
    )

    # ä¿®æ­£å®Ÿè£…ã§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
    fixed = FixedSingleTimeStepPrediction("test_prediction", attention_paths)

    # pickleç›´åˆ—åŒ–/é€†ç›´åˆ—åŒ–
    serialized = pickle.dumps(fixed)
    deserialized = pickle.loads(serialized)

    # eye2vecã®context_model.pyã¨åŒæ§˜ã®è¾æ›¸ã‚¢ã‚¯ã‚»ã‚¹ã‚’ãƒ†ã‚¹ãƒˆ
    path_context = deserialized.attention_paths[0]

    try:
        accessed_vector = path_context["vector"]
        print(f"âœ… path_context['vector'] æˆåŠŸ: {type(accessed_vector)}")

        # tobytes()ãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆï¼ˆeye2vecã§ä½¿ç”¨ï¼‰
        if hasattr(accessed_vector, "tobytes"):
            vector_bytes = accessed_vector.tobytes()
            print(f"âœ… vector.tobytes() æˆåŠŸ: {len(vector_bytes)} bytes")
        else:
            print("âŒ vector.tobytes() å¤±æ•—: tobytesBattribute not found")

        return True

    except Exception as e:
        print(f"âŒ è¾æ›¸ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {e}")
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("è¾æ›¸å¤‰æ›ä¿®æ­£ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")

    # ã‚ªãƒªã‚¸ãƒŠãƒ«å®Ÿè£…ãƒ†ã‚¹ãƒˆ
    orig_vector_numpy, orig_source_numpy = test_original_implementation()

    # ä¿®æ­£å®Ÿè£…ãƒ†ã‚¹ãƒˆ
    fixed_vector_numpy, fixed_source_numpy = test_fixed_implementation()

    # è¾æ›¸ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
    dict_access_success = test_dict_access_compatibility()

    print("\n=== ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ ===")
    print(f"ã‚ªãƒªã‚¸ãƒŠãƒ«å®Ÿè£… - vector is numpy: {orig_vector_numpy}")
    print(f"ã‚ªãƒªã‚¸ãƒŠãƒ«å®Ÿè£… - source_vector is numpy: {orig_source_numpy}")
    print(f"ä¿®æ­£å®Ÿè£… - vector is numpy: {fixed_vector_numpy}")
    print(f"ä¿®æ­£å®Ÿè£… - source_vector is numpy: {fixed_source_numpy}")
    print(f"è¾æ›¸ã‚¢ã‚¯ã‚»ã‚¹äº’æ›æ€§: {dict_access_success}")

    if fixed_vector_numpy and fixed_source_numpy and dict_access_success:
        print("\nğŸ‰ ä¿®æ­£æ¡ˆã¯æœ‰åŠ¹ã§ã™ï¼")
        return True
    else:
        print("\nâŒ ä¿®æ­£æ¡ˆã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
